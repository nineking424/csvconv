============================================================
PRD.txt
Program Requirement Document
============================================================

프로그램명: csvconv
버전: v1.0 (Initial)
작성일: 2026-02-10
목적: 대용량 CSV 및 tar.gz 아카이브를 메모리 효율적으로 Parquet 또는 CSV로 변환

------------------------------------------------------------
1. 배경 및 문제 정의
------------------------------------------------------------

현행 ETL 및 데이터 파이프라인 환경에서 다음과 같은 문제가 존재한다.

- CSV 파일은 디스크 I/O 및 쿼리 성능 측면에서 비효율적임
- 대용량 CSV 파일은 전체 로딩 시 메모리 사용량 폭증 위험
- tar.gz 형태로 다수 CSV가 묶여 제공되는 경우가 많음
- DuckDB 등 일부 도구는 OS / glibc 제약으로 사용이 어려움
- Python 기반 스크립트는 배포 및 실행 환경 관리가 번거로움

이를 해결하기 위해 다음 목표를 갖는 변환 도구가 필요하다.

------------------------------------------------------------
2. 목표 (Goals)
------------------------------------------------------------

- 스트리밍 기반 CSV → Parquet 변환
- 메모리 사용량 상한을 제어 가능
- tar.gz 내부 CSV 처리 지원
- tar 내부 CSV의 스키마를 사전 추론 후 고정
- 단일 실행 파일(PEX) 형태로 배포
- CentOS 8 / Rocky / Alma Linux 환경에서 안정적 실행

------------------------------------------------------------
3. 비목표 (Non-Goals)
------------------------------------------------------------

- Spark, Hadoop 등 분산 처리 프레임워크 의존
- GUI 제공
- 실시간 스트리밍 처리 (Kafka 등)
- CSV 외 포맷(JSON, XML 등) 입력 지원

------------------------------------------------------------
4. 지원 유즈케이스
------------------------------------------------------------

### 4.1 CSV → Parquet
- 단일 CSV 파일을 스트리밍 방식으로 Parquet 파일로 변환
- Row Group 단위로 flush
- 전체 파일을 메모리에 적재하지 않음

### 4.2 tar.gz → Parquet
- tar.gz 내부에 포함된 다수 CSV 파일 처리
- 1단계: tar 내부 CSV 스키마 사전 추론
- 2단계: 추론된 스키마를 모든 CSV에 고정 적용
- CSV 파일 단위로 Parquet 생성

### 4.3 tar.gz → CSV
- tar.gz 내부 CSV를 개별 CSV로 풀어서 저장
- gzip 압축 옵션 지원 (csv.gz)

------------------------------------------------------------
5. 기능 요구사항
------------------------------------------------------------

### 5.1 입력 포맷
- csv
- tar.gz (내부 파일은 csv)

### 5.2 출력 포맷
- parquet
- csv
- csv.gz

### 5.3 스트리밍 처리
- PyArrow CSV streaming API 사용
- block_size 기반 읽기
- ParquetWriter를 통한 incremental write

### 5.4 스키마 처리
- tar.gz 입력 시:
  - 첫 번째 CSV 파일 기준 스키마 추론
  - 추론된 스키마를 모든 파일에 고정 적용
- 타입 불일치 시 오류 처리 또는 실패 로그 기록

### 5.5 메모리 관리
- 기본 메모리 상한: PyArrow 기본값 사용
- 옵션으로 다음 항목 조정 가능:
  - CSV block_size (MB)
  - Parquet row_group_size

------------------------------------------------------------
6. CLI 인터페이스
------------------------------------------------------------

### 6.1 기본 실행 형태

csvconv [OPTIONS]

### 6.2 주요 옵션

- --input <path>
- --output <path>
- --input-type [csv|tar.gz]
- --output-type [parquet|csv]
- --gzip (csv 출력 시 gzip 압축)
- --block-size-mb <int>
- --row-group-size <int>
- --schema-sample-rows <int>
- --log-level [INFO|WARN|ERROR]

------------------------------------------------------------
7. 에러 처리 및 로깅
------------------------------------------------------------

- 파일 단위 에러 격리
- 스키마 불일치 시 명확한 에러 메시지 출력
- STDOUT/STDERR 로그 분리 가능
- 변환 성공/실패 요약 로그 제공

------------------------------------------------------------
8. 성능 요구사항
------------------------------------------------------------

- 입력 파일 크기에 비례한 선형 처리 시간
- 메모리 사용량은 입력 파일 크기와 무관하게 상한 유지
- NFS 환경에서도 안정적 동작

------------------------------------------------------------
9. 배포 요구사항
------------------------------------------------------------

### 9.1 단일 바이너리
- PEX 기반 패키징
- Python 런타임 포함
- 외부 의존성 없음

### 9.2 실행 환경
- CentOS 8
- Rocky Linux 8
- AlmaLinux 8

------------------------------------------------------------
10. 기술 스택
------------------------------------------------------------

- Language: Python 3.8+
- Core Library: PyArrow
- Packaging: PEX
- Compression: gzip
- Archive Handling: tarfile

------------------------------------------------------------
11. 보안 및 안정성
------------------------------------------------------------

- 임시 파일 최소화
- tar 압축 해제 시 경로 탈출(path traversal) 방지
- 입력 파일 검증 수행

------------------------------------------------------------
12. 향후 확장 고려사항
------------------------------------------------------------

- Iceberg 테이블 직접 적재
- 멀티 프로세스 병렬 변환
- Schema Registry 연동
- Metrics (Prometheus) 노출

============================================================
End of PRD.txt
============================================================
